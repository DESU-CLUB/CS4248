# -*- coding: utf-8 -*-
"""Evaluation for Custom Model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16OpmUejPrSpu7JwWggI655ZAW7cVN7Vs
"""

pip install evaluate

pip install rouge-score

import torch
import numpy as np
import evaluate
from sklearn.metrics.pairwise import cosine_similarity

# Hugging Face metrics
bleu = evaluate.load("bleu")
meteor = evaluate.load("meteor")
rouge = evaluate.load("rouge")
exact = evaluate.load("exact_match")

def evaluate_custom_encoder_decoder(
    df,
    encoder,            # your encoder model: text â†’ embedding
    decoder,            # your decoder model: embedding â†’ text
    llama_vectorizer,   # precomputed LLaMA emoji vectors (for ground truth)
    decoder_labels,     # ground truth decoded texts (e.g., emoji captions)
    use_tokenizer=False,
    tokenizer=None
):
    predictions = []
    references = []
    cosine_scores = []

    for idx, row in df.iterrows():
        input_text = row["text"]
        target_vector = llama_vectorizer[idx]           # from LLaMA
        target_text = decoder_labels[idx]               # demojized text version

        # Encode: text â†’ embedding
        with torch.no_grad():
            embedding = encoder(input_text)
            if isinstance(embedding, tuple):  # if encoder returns (hidden, pooled)
                embedding = embedding[0]

        # Decode: embedding â†’ text
        if use_tokenizer and tokenizer:
            # decoder is a LM like T5
            input_tokens = tokenizer(input_text, return_tensors="pt").to(embedding.device)
            decoded_ids = decoder.generate(**input_tokens)
            decoded_text = tokenizer.decode(decoded_ids[0], skip_special_tokens=True)
        else:
            decoded_text = decoder(embedding)

        predictions.append(decoded_text)
        references.append(target_text)

        # Cosine similarity between encoder output and LLaMA vector
        sim = cosine_similarity(
            embedding.detach().cpu().numpy().reshape(1, -1),
            target_vector.reshape(1, -1)
        )[0][0]
        cosine_scores.append(sim)

    # HF Metrics
    results = {
        "BLEU": bleu.compute(predictions=predictions, references=[[r] for r in references])["bleu"],
        "METEOR": meteor.compute(predictions=predictions, references=references)["meteor"],
        "ROUGE-L": rouge.compute(predictions=predictions, references=references)["rougeL"],
        "Exact Match": exact.compute(predictions=predictions, references=references)["exact_match"],
        "Cosine Similarity (Encoder)": float(np.mean(cosine_scores))
    }

    print("\nðŸ§ª Evaluation Results (Custom Pipeline):")
    for k, v in results.items():
        print(f"{k}: {v:.4f}")

    return results

results = evaluate_custom_encoder_decoder(
    df=my_data_df,                            # must contain "text" column
    encoder=my_encoder,                       # your encoder wrapper
    decoder=my_decoder,                       # your decoder wrapper
    llama_vectorizer=llama_vectors,           # (N, D) embeddings from LLaMA
    decoder_labels=emoji_text_descriptions,   # ground truth captions
    use_tokenizer=False,                      # decoder is not HF model
    tokenizer=None
)